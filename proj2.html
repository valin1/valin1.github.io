<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Modeled off of fimbo.-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title> 194-26 Project 2 </title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css">
    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.1/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
    <style type="text/css" media="screen">
@import url('https://fonts.googleapis.com/css?family=Nanum+Gothic');

body {
    font-family: 'Nanum Gothic', sans-serif;
    padding:0px;
    margin:0px;
    max-width:100vw;
    overflow-x:hidden;
    scroll-behavior: smooth;
}

a {
    color: #5b93b0;
    -webkit-transition: all 0.3s ease-in-out;
    transition: all 0.3s ease-in-out;
    text-decoration:none;
}

a:hover, a:focus, a:active {
    color: #375d70;
}

a:hover, a:active {
    outline: 0;
}

h1, h2, h3 {
    color: #4d4f52;
}

h4 {
    color: #4d4f52;
    line-height: 1.5;
}

header {
    width:92vw;
    padding:6vh 4vw;
    position:fixed;
    background:transparent;
    color:#fff;
    transition:0.4s ease-in-out;
    z-index:2;
}
header table {
    width:100%;
}

#photoprojects {
    width:92vw;
    padding:6vh 4vw;
    font-weight:bold;
}
#photoprojects h1 {
    padding:5px 0px;
    width:100%;
}

#footer {
    width:100%;
    padding:10vh 0px;
    text-align:center;
}
#footer a {
    color:#375d70;
    text-decoration:none;
}
::placeholder {
    color:#000;
}
button:focus {
    outline:none;
}
::-webkit-scrollbar {
    width:5px;
    height:5px;
}
::-webkit-scrollbar-track {
    background: #f1f1f1; 
}
::-webkit-scrollbar-thumb {
    background: rgb(0, 0, 0); 
}
::-webkit-scrollbar-thumb:hover {
    background: rgba(0, 0, 0,0.8); 
}

#container {
    text-align: center;
}
figure {
    display: inline-block;
    padding: 0px;
}
figcaption {
    margin: 10px 0 0 0;
    font-family: 'Nanum Gothic', sans-serif;
    color: #4d4f52;
}

img:hover {
    transform: scale(1.1);
    -ms-transform: scale(1.1);
    -webkit-transform: scale(1.1);
    -moz-transform: scale(1.1);
    -o-transform: scale(1.1);
}
img {
    transition: transform 0.2s;
    -webkit-transition: -webkit-transform 0.2s;
    -moz-transition: -moz-transform 0.2s;
    -o-transition: -o-transform 0.2s;
}
code {
    padding: .2rem .4rem;
    font-size: 90%;
    color: #2a6e9c;
    background-color: #f8f9fa;
    border-radius: .25rem;
}

.row {
  display: flex;
}

.column {
  flex: 50%;
  padding: 5px;
  text-align: center;
}

.column_3 {
  flex: 33.33%;
  padding: 5px;
  text-align: center;
}
.column_5 {
  flex: 20%;
  padding: 5px;
  text-align: center;
}


    </style>
</head>
<body>
    <div id="photoprojects">
        <h1 style= "text-align: center">Project 02: Fun with Filters and Frequencies! </h1>
        <h3 style= "text-align: center">Vanessa Lin</h3>

        <h2>Overview</h2>
        I have created these images below by playing around with filters and frequencies, enjoy!

        <h2>1. Fun with Filters</h2>
        <h3>1.1 </h3>
        <div id="container">
            <figure>
                <img src="data/cameraman.png" width = "75%"/>
                <figcaption>original camera man image</figcaption>
            </figure>
        </div>
        For this <code>cameraman.png</code> image, through using derivatives in the x and y directions, a gradient magnitude image and edge image was created. First, I convolved the original image with  <code>[[1, -1]]</code> for the partial derivative in x and then, convolved the original image with <code>[[1][-1]]</code> for the partial derivative in y. The gradient image was sproduced by squaring the partial derivatives of x and y, adding the squared partial derivatives together, and then square rooting the sum. The edge image was created by binarizing the gradient magnitude image based on a certain threshold, which I defined as 0.15. 
        <div id="container">
            <figure>
                <img src="produced_imgs/im_part_x.png" width="50%"/>
                <figcaption>partial derivative in x</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/im_part_y.png" width="50%"/>
                <figcaption>partial derivative in y</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/camera_man_grad.png" width="50%" />
                <figcaption>gradient magnitude image</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/bin_camera_man.png" width="50%"/>
                <figcaption>edge image</figcaption>
            </figure>
        </div>

        <h3>1.2 </h3>
        In the edge image produced in part 1.1, we can see that the results were particularly noisy, so in this part, I will be using a Gaussian filter to hopefully get a better edge image. I used a Gaussian filter of size 15 by 15 with sigma value of 1.5. First, I convolved the original image with this Gaussian filter to get a blurrier/smoothed version of the original <code>cameraman.png</code> image. Afterwards I convolved the partial derivatives in x and y like before and produced this edge image with a threshold of 0.17:
        <div id="container">
            <figure>
                <img src="produced_imgs/camera_man_grad_smoothed.png" width="50%"/>
                <figcaption>gradient magnitude image</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/bin_camera_man_smoothed.png" width="50%"/>
                <figcaption>edge image</figcaption>
            </figure>
        </div>
        From this image, we can see that the edges are a lot more pronounced and thicker than the edge image in part 1.1 and there is less noise in this edge image and kept more details/edges in the background behind the camera man. 
        <div id="container">
            <figure>
                <img src="produced_imgs/dGdx.png" width="50%"/>
                <figcaption>gaussian convolved with [[1 -1]]</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/dGdy.png" width="50%"/>
                <figcaption>gaussian convolved with [[1] [-1]]</figcaption>
            </figure>
        </div>
        Here are the images from running with a single convolution through creating a derivative of the Gaussian filters, with the same threshold of 0.17:
        <div id="container">
            <figure>
                <img src="produced_imgs/camera_man_grad_one_smoothed.png" width="50%"/>
                <figcaption>gradient magnitude image with single convolution</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/bin_camera_man_one_smoothed.png" width="50%"/>
                <figcaption>edge image with single convolution</figcaption>
            </figure>
        </div>

        <h3>1.3 </h3>
        Here, using the gradient and edge detection filters from 1.1 and 1.2, I created an automated image straightening function. In the function, there is a set of 18 angles from -14 to 14 and for each angle in the set, I rotate the original image by that angle. After the rotation, I crop out the center of the rotated image to remove the black artifacts, and then I use the Gaussian derivatives and convolve them with the cropped image to get the derivative of each pixel in the x and y directions. Using the gradient direction formula which is <code>np.arctan2(dy, dx)</code>, I found the gradient angle of each pixel, obtaining a list of gradient angles, and created a histogram from that list. I counted the number of angles that were in the 89 to 90 (and -89 to -90) bucket and the 0 to 1 (and 0 to -1) bucket, because those angles are the vertical and horizontal edges that we want to straighten the image. I then kept track of the angle that had the maximum number of angles, which were vertical/horizontal edges, and returned the angle.

        <div class="row">
          <div class="column">
            <br>
            <img src="data/facade.jpg" width = "35%" />
            <figcaption>original facade image</figcaption>
          </div>
          <div class="column">
            <img src="produced_imgs/facade_hist.png"  width = "45%" />
            <figcaption>orientation histogram of original facade</figcaption>
          </div>
        </div>

        <div class="row">
          <div class="column">
            <br>
                <img src="produced_imgs/facade_straight.png" width="35%"/>
                <figcaption>straightened facade image (rotated by -3 degrees)</figcaption>
          </div>
          <div class="column">
                <img src="produced_imgs/facade_straight_hist.png" width="45%"/>
                <figcaption>orientation histogram of straightened facade</figcaption>
          </div>
        </div>

        As you can see after the image is straightened, the number of angles at the vertical and horizontal edges appear to be much more even compared to the original tilted photo's histogram. Since I use a lot of angles, the runtime of this straightening algorithm takes around a minute or so to run to figure out the best angle.
        Here are some more rotations:

        <div class="row">
          <div class="column">
            <br>
            <img src="data/sunrise.jpg" width = "40%" />
            <figcaption>original sunrise image</figcaption>
          </div>
          <div class="column">
            <img src="produced_imgs/sunrise_hist.png"  width = "45%" />
            <figcaption>orientation histogram of original sunrise</figcaption>
          </div>
        </div>

        <div class="row">
          <div class="column">
            <br>
                <img src="produced_imgs/sunrise_straight.png" width="40%"/>
                <figcaption>straightened sunrise image (rotated by -12 degrees)</figcaption>
          </div>
          <div class="column">
                <img src="produced_imgs/sunrise_straight_hist.png" width="45%"/>
                <figcaption>orientation histogram of straightened sunrise</figcaption>
          </div>
        </div>

        <div class="row">
          <div class="column">
            <br>
            <img src="data/brooklyn.jpg" width = "40%" />
            <figcaption>original brooklyn bridge image</figcaption>
          </div>
          <div class="column">
            <img src="produced_imgs/brooklyn_hist.png"  width = "45%" />
            <figcaption>orientation histogram of original brooklyn bridge</figcaption>
          </div>
        </div>

        <div class="row">
          <div class="column">
            <br>
                <img src="produced_imgs/brooklyn_straight.png" width="40%"/>
                <figcaption>straightened brooklyn bridge image (rotated by 12 degrees)</figcaption>
          </div>
          <div class="column">
                <img src="produced_imgs/brooklyn_straight_hist.png" width="45%"/>
                <figcaption>orientation histogram of straightened brooklyn bridge</figcaption>
          </div>
        </div>

        Below, this is a failed case of my automated straightening algorithm because the photo is taken at such an angle, where the lines in the Arc de Triomphe aren't all necessarily parallel to each other, so my function is only able to straighten the image based on the first horizontal line above the arch. However as you can see the top edge of Arc de Triomphe is not straightened at all.
        <div class="row">
          <div class="column">
            <br>
            <img src="data/hd_triomphe.jpg" width = "40%" />
            <figcaption>original triomphe image</figcaption>
          </div>
          <div class="column">
            <img src="produced_imgs/hd_triomphe_hist.png"  width = "45%" />
            <figcaption>orientation histogram of original triomphe</figcaption>
          </div>
        </div>

        <div class="row">
          <div class="column">
            <br>
                <img src="produced_imgs/hd_triomphe_straight.png" width="40%"/>
                <figcaption>straightened triomphe image (rotated by -8 degrees)</figcaption>
          </div>
          <div class="column">
                <img src="produced_imgs/hd_triomphe_straight_hist.png" width="45%"/>
                <figcaption>orientation histogram of straightened triomphe</figcaption>
          </div>
        </div>

        <h2>2. Fun with Frequencies</h2>
        <h3>2.1 </h3>
        To create sharpened images, I convolved the image with a Gaussian to get a blurred version of the image. Afterwards, I subtracted the blurred image from the original and got the high frequencies of the image, which I then added to the original image to create a more sharpened image. For the single convolution operation, I made an unmask filter through <code>(1+alpha)*unit_impulse - alpha*gaussian</code>. I used an alpha of 1 for these images.

        <div id="container">
            <figure>
                <img src="data/taj.jpg" width="50%"/>
                <figcaption>original taj mahal</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/taj_sharp.jpg" width="50%"/>
                <figcaption>sharpened taj mahal</figcaption>
            </figure>
        </div>

        <div id="container">
            <figure>
                <img src="data/baby.jpg" width="100%"/>
                <figcaption>original baby</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/baby_sharp.jpg" width="100%"/>
                <figcaption>sharpened baby</figcaption>
            </figure>
        </div>    

        <div id="container">
            <figure>
                <img src="data/audrey.jpg" width="100%"/>
                <figcaption>original audrey hepburn</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/audrey_sharp.jpg" width="100%"/>
                <figcaption>sharpened audrey hepburn</figcaption>
            </figure>
        </div> 

        <div id="container">
            <figure>
                <img src="data/hamster.jpg" width="100%"/>
                <figcaption>original hamster</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/hamster_sharp.jpg" width="100%"/>
                <figcaption>sharpened hamster</figcaption>
            </figure>
        </div> 
    For images that contained images of people, like the <code>baby.jpg</code> and <code>audrey.jpg</code>, the sharpening algorithm appears to add more color to the final sharpened images, or at least the algorithm adds more information, which is not necessarily good if you want to keep the original colors. However this extra color helps add the details that were not as easily seen before in the original images, like for the baby you can see the eyebrows more clearly than before and the outline of his face is more defined. Here is an evaluation of a sharp image, using an alpha of 1:

        <div id="container">
            <figure>
                <img src="data/city.jpg" width="100%"/>
                <figcaption>original city</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/city_blurred.jpg" width="100%"/>
                <figcaption>blurred city</figcaption>
            </figure>
        </div>
        <div id="container">
            <figure>
                <img src="produced_imgs/city_high_freq.jpg" width="100%"/>
                <figcaption>high frequencies of city</figcaption>
            </figure>
            <figure>
                <img src="produced_imgs/city_sharp.jpg" width="100%"/>
                <figcaption>sharpened city</figcaption>
            </figure>
        </div>   

    Compared to the original image, the sharpened image is not as clear and defined as the original image and has a sort of red residue blur on the image; however, compared to the blurred version, the sharpened version has more defined edges compared to the blurred version. Since the image sharpening is ran on the blurred image, some information along with the high frequencies from the original image is lost, so you can see that in the sharpened image, the color is slightly stronger.
    <h3>2.2 </h3>

    For this part, I created hybrid images through aligning images based on certain features, like eyes and face, and then I found the high frequencies of one image and the low frequencies of the other image and then combined the frequencies together to create a hybrid image result. I used the code alignment code given to us to align the images. For the combination of Park Seo Joon and IU hybrid, I used a gaussian filter of 30x30 with sigma 5 for IU and sigma 7 for Park Seo Joon. 


    <div class="row">
      <div class="column_3">
        <br>
        <img src="data/iu.jpg" width = "100%" />
        <figcaption>image of IU</figcaption>
      </div>
      <div class="column_3">
        <img src="data/psj.jpg"  width = "45%" />
        <figcaption>image of Park Seo Joon</figcaption>
      </div>
      <div class="column_3">
        <img src="produced_imgs/hybrid_iu_psj.png"  width = "45%" />
        <figcaption>hybrid image of IU and Park Seo Joon</figcaption>
      </div>
    </div>

    For the combination of angry Gon and happy Gon, I used a gaussian filter of 30x30 with sigma 5 for angry Gon and sigma 15 for happy Gon. 

    <div class="row">
      <div class="column_3">
        <br>
        <img src="data/angrygon.jpg" width = "100%" />
        <figcaption>image of angry Gon</figcaption>
      </div>
      <div class="column_3">
        <br>
        <img src="data/happygon.jpg"  width = "100%" />
        <figcaption>image of happy Gon</figcaption>
      </div>
      <div class="column_3">
        <img src="produced_imgs/hybrid_gon.png"  width = "100%" />
        <figcaption>hybrid image of the Gons</figcaption>
      </div>
    </div>

    Here is a failed hybrid image, where I tried to perform a hybrid between a squirrel and bunny, at close glance, the bunny looks more like a squirrel with bunny ears and still resembles a squirrel. Also, this case failed because their body shapes were slightly different given that the squirrel has a tall bushy tail that protrudes out, while the bunny has a more ball-like shape. 

    <div class="row">
      <div class="column_3">
        <br>
        <img src="data/rabbit.jpg" width = "100%" />
        <figcaption>image of rabbit</figcaption>
      </div>
      <div class="column_3">
        <br>
        <img src="data/squirrel.jpg"  width = "100%" />
        <figcaption>image of squirrel</figcaption>
      </div>
      <div class="column_3">
        <br>
        <img src="produced_imgs/hybrid_rabbit_squirrel.png"  width = "100%" />
        <figcaption>hybrid image of rabbit-squirrel</figcaption>
      </div>
    </div>


    Here is the log magnitude of the Fourier transform of the images, from input to filtered, to the hybrid image. 

    <div class="row">
      <div class="column_5">
        <br>
        <img src="produced_imgs/angry_fft.png"  width = "100%" />
        <figcaption>fft of angry gon</figcaption>
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/happy_fft.png" width = "100%" />
        <figcaption>fft of happy gon</figcaption>
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/high_fft.png" width = "100%" />
        <figcaption>high fft of angry gon</figcaption>
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/low_fft.png"  width = "100%" />
        <figcaption>low fft of happy gon</figcaption>
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/hybrid_fft.png"  width = "100%" />
        <figcaption>fft of hybrid gon</figcaption>
      </div>
    </div>

    <h3>2.3 </h3>
    Here, I produced Gaussian and Laplacian stacks. For the Gaussian stack, I applied a Gaussian filter of size 30x30 with sigma of 3 over the previous image with the first image of the stack being the original image. For the Laplacian stack, I subtracted the Gaussian image of the next index from the current index to get the current Laplacian level until the last level where I just took the Gaussian image of that current index. Here are the Gaussian stack and Laplacian stack of the Salvador Dali painting of Lincoln and Gala.

    <div class="row">
      <div class="column_5">
        <br>
        <img src="produced_imgs/lincoln_gaussian_stack0.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/lincoln_gaussian_stack1.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/lincoln_gaussian_stack2.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/lincoln_gaussian_stack3.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/lincoln_gaussian_stack4.png"  width = "100%" />
      </div>
    </div>

    <div class="row">
      <div class="column_5">
        <br>
        <img src="produced_imgs/lincoln_laplace_stack0.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/lincoln_laplace_stack1.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/lincoln_laplace_stack2.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/lincoln_laplace_stack3.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/lincoln_laplace_stack4.png"  width = "100%" />
      </div>
    </div>

    Here are the Gaussian stack and Laplacian stack of the hybrid Gon image (angry and happy).

    <div class="row">
      <div class="column_5">
        <br>
        <img src="produced_imgs/gon_gaussian_stack0.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/gon_gaussian_stack1.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/gon_gaussian_stack2.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/gon_gaussian_stack3.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/gon_gaussian_stack4.png"  width = "100%" />
      </div>
    </div>
    <div class="row">
      <div class="column_5">
        <br>
        <img src="produced_imgs/gon_laplace_stack0.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/gon_laplace_stack1.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/gon_laplace_stack2.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/gon_laplace_stack3.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/gon_laplace_stack4.png"  width = "100%" />
      </div>
    </div>

    <h3>2.4 </h3>
    For multiresolution blending, using the Gaussian stack and Laplacian stack functions from before, I found the Laplacian stack of both the images that we want to blend and the Gaussian stack of the mask. For each level of the stack, I multiply the <code>mask</code> with the left image at that level and then multiply <code>1 - mask</code> with the right image of that level (may not necessarily be left or right depends on what mask you are using). Afterwards, I add the products together and add to the previous sum of masks and Laplacian images. At the end, we get a multiresolution blend between the images.

    <div id="container">
        <figure>
        <img src="produced_imgs/blend_orple.png"  width = "100%" />
        <figcaption>blended image of orple</figcaption>
        </figure>
    </div>



    <div class="row">
      <div class="column_3">
        <br>
        <img src="data/basketball.png" width = "50%" />
        <figcaption>image of basketball</figcaption>
      </div>
      <div class="column_3">
        <br>
        <img src="data/soccer.png"  width = "50%" />
        <figcaption>image of soccer</figcaption>
      </div>
      <div class="column_3">
        <br>
        <img src="produced_imgs/blend_basket_soccer.png"  width = "50%" />
        <figcaption>blended image of basket soccer ball</figcaption>
      </div>
    </div>

    <div class="row">
      <div class="column_3">
        <br>
        <img src="data/beach.jpg" width = "100%" />
        <figcaption>image of beach</figcaption>
      </div>
      <div class="column_3">
        <br>
        <img src="data/louvre.jpg"  width = "100%" />
        <figcaption>image of louvre</figcaption>
      </div>
      <div class="column_3">
        <br>
        <img src="produced_imgs/blend_louvre_beach.png"  width = "100%" />
        <figcaption>blended image of louvre at the beach</figcaption>
      </div>
    </div>

    Below is the illustrated process of blending the Louvre and the beach background together. 
    <div class="row">
      <div class="column_5">
        <br>
        <img src="produced_imgs/beach_laplace_stack0.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/beach_laplace_stack1.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/beach_laplace_stack2.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/beach_laplace_stack3.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/beach_laplace_stack4.png"  width = "100%" />
      </div>
    </div>

    <div class="row">
      <div class="column_5">
        <br>
        <img src="produced_imgs/louvre_laplace_stack0.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/louvre_laplace_stack1.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/louvre_laplace_stack2.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/louvre_laplace_stack3.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/louvre_laplace_stack4.png"  width = "100%" />
      </div>
    </div>

    <div class="row">
      <div class="column_5">
        <br>
        <img src="produced_imgs/blend_all_laplace_stack0.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/blend_all_laplace_stack1.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/blend_all_laplace_stack2.png" width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/blend_all_laplace_stack3.png"  width = "100%" />
      </div>
      <div class="column_5">
        <br>
        <img src="produced_imgs/blend_all_laplace_stack4.png"  width = "100%" />
      </div>
    </div>


    </div>
    <div id="footer">
        vanessa lin &copy 2020 <br> 
    </div>
</body>
</html>